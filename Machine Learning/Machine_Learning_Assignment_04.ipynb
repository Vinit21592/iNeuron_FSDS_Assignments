{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70196caa",
   "metadata": {},
   "source": [
    "### 1. What are the key tasks involved in getting ready to work with machine learning modeling?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fabb8f",
   "metadata": {},
   "source": [
    "There are several key tasks involved in getting ready to work with machine learning modeling:\n",
    "\n",
    "1. **Define the problem:** The first step is to define the problem that you want to solve with machine learning. Clearly defining the problem will help you determine the type of data you need and the type of algorithm you should use.\n",
    "\n",
    "2. **Gather data:** Once you have defined the problem, the next step is to gather the necessary data. You need to ensure that the data you collect is accurate, relevant, and representative of the problem you are trying to solve.\n",
    "\n",
    "3. **Data cleaning and preprocessing:** Before you can use the data for modeling, you need to clean and preprocess it. This includes tasks such as removing missing values, handling outliers, scaling the data, and encoding categorical variables.\n",
    "\n",
    "4. **Feature engineering:** Feature engineering involves selecting and transforming the relevant features in the data to improve the performance of the model. This may involve creating new features, selecting the most important features, and transforming the features to better suit the model.\n",
    "\n",
    "5. **Model selection:** There are various machine learning models to choose from, and you need to select the one that is best suited to your problem. This involves understanding the strengths and weaknesses of different models and selecting the one that best meets your needs.\n",
    "\n",
    "6. **Model training:** Once you have selected the model, you need to train it on the data. This involves feeding the model with the input data and adjusting the model's parameters to minimize the error.\n",
    "\n",
    "7. **Model evaluation:** After training the model, you need to evaluate its performance to see how well it is doing. This involves testing the model on a separate test dataset and comparing its predicted output with the actual output.\n",
    "\n",
    "8. **Model deployment:** Finally, you need to deploy the model in a production environment, where it can be used to make predictions on new data. This involves integrating the model with other software and ensuring that it is scalable and reliable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f29fc62",
   "metadata": {},
   "source": [
    "### 2. What are the different forms of data used in machine learning? Give a specific example for each of them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2294e429",
   "metadata": {},
   "source": [
    "**There are three main forms of data used in machine learning:**\n",
    "\n",
    "**Numeric data:** Numeric data is represented by numbers and can be either continuous or discrete. Examples of continuous numeric data include height, weight, and temperature, while examples of discrete numeric data include the number of people in a household, the number of cars in a parking lot, and the number of items in a shopping cart.\n",
    "\n",
    "**Categorical data:** Categorical data is represented by labels or categories, and can be nominal or ordinal. Nominal categorical data has no natural order or ranking, such as colors or breeds of dogs. Ordinal categorical data has a natural order or ranking, such as education level (elementary, high school, college).\n",
    "\n",
    "**Text data:** Text data is represented by natural language text, such as emails, social media posts, or product reviews. Text data can be transformed into numerical form through techniques such as tokenization, stemming, and vectorization, so that it can be used in machine learning models.\n",
    "\n",
    "**Examples of each type of data:**\n",
    "\n",
    "**Numeric data:** A machine learning model to predict housing prices might use numeric data such as the number of bedrooms, square footage, and age of the house.\n",
    "\n",
    "**Categorical data:** A machine learning model to predict customer churn might use categorical data such as the customer's gender, location, and subscription plan.\n",
    "\n",
    "**Text data:** A machine learning model to classify movie reviews as positive or negative might use text data from the reviews themselves. For example, the model might analyze the sentiment of the words used in the review to make its prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f61d54",
   "metadata": {},
   "source": [
    "### 3. Distinguish:\n",
    "\n",
    "1. Numeric vs. categorical attributes\n",
    "\n",
    "2. Feature selection vs. dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14deac08",
   "metadata": {},
   "source": [
    "The following are the differences between:\n",
    "\n",
    "1. **Numeric vs. categorical attributes:**\n",
    "* Numerical data are values obtained for quantitative variable, and carries a sense of magnitude related to the context of the variable (hence, they are always numbers or symbols carrying a numerical value).\n",
    "* Categorical data are values obtained for a qualitative variable. categorical data numbers do not carry a sense of magnitude.\n",
    "* Numerical data always belong to either ordinal, ratio, or interval type, whereas categorical data belong to nominal type. Methods used to analyse quantitative data are different from the methods used for categorical data, even if the principles are the same at least the application has significant differences.\n",
    "* Numerical data are analysed using statistical methods in descriptive statistics, regression, time series and many more.For categorical data usually descriptive methods and graphical methods are employed. Some non-parametric tests are also used.\n",
    "2. **Feature selection vs. dimensionality reduction:**\n",
    "* Feature selection you just select a subset of the original feature set, without any manipulation of the data on the other hand.\n",
    "* Dimensionality reduction is typically choosing a new representation within which you can describe most but not all of the variance within your data, thereby retaining the relevant information, while reducing theamount of information necessary to represent it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0675bce2",
   "metadata": {},
   "source": [
    "### 4. Make quick notes on any two of the following:\n",
    "\n",
    "1. The histogram\n",
    "\n",
    "2. Use a scatter plot\n",
    "\n",
    "3. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfc7b38",
   "metadata": {},
   "source": [
    "The Quick notes on the following three topics is:\n",
    "\n",
    "**The histogram:** A Histogram is a graphical representation that organizes a group of data points into user-specified ranges. Similar in appearance to a bar graph, the histogram condenses a data series into an easily interpreted visual by taking many data points and grouping them into logical ranges or bins.\n",
    "\n",
    "**Use a scatter plot:** A scatter plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. Scatter plots are used to observe relationships between variables.\n",
    "\n",
    "**PCA:** Principal Component Analysis or PCA is a widely used technique for dimensionality reduction of the large data set. Reducing the number of components or features costs some accuracy and on the other hand, it makes the large data set simpler, easy to explore and visualize."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "546f0c8c",
   "metadata": {},
   "source": [
    "### 5. Why is it necessary to investigate data? Is there a discrepancy in how qualitative and quantitative data are explored?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01286e2",
   "metadata": {},
   "source": [
    "If your data set is messy, building models will not help you to solve your problem. What will happen is Garbage In, Garbage Out. In order to build a powerful machine learning algorithm. We need to explore and understand our data set before we define a predictive task and solve it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e8bf77",
   "metadata": {},
   "source": [
    "### 6. What are the various histogram shapes? What exactly are â€˜bins&#39;?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51409423",
   "metadata": {},
   "source": [
    "The different types of a Histogram are:\n",
    "\n",
    "1. Uniform Histogram\n",
    "2. Symmetric Histogram\n",
    "3. Bimodal Histogram\n",
    "4. Probability Histogram.\n",
    "\n",
    "The bin in a histogram is the choice of unit and spacing on the X-axis. All the data in a probability distribution represented visually by a histogram is filled into the corresponding bins. The height of each bin is a measurement of the frequency with which data appears inside the range of that bin in the distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ab687",
   "metadata": {},
   "source": [
    "### 7. How do we deal with data outliers?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127d8184",
   "metadata": {},
   "source": [
    "We can use Z-Score or any of below methods to deal with data outliers:\n",
    "\n",
    "**Univariate Method:** This method looks for data points with extreme values on one variable.\n",
    "\n",
    "**Multivariate Method:** Here, we look for unusual combinations of all the variables.\n",
    "\n",
    "**Minkowski Error:** This method reduces the contribution of potential outliers in the training process.\n",
    "\n",
    "**Z-Score:** This can be done with just one line code as we have already calculated the Z-score.\n",
    "\n",
    "boston_df_o = boston_df_o[(z < 3).all(axis=1)]\n",
    "\n",
    "**IQR Score:** Calculate IQR score to filter out the outliers by keeping only valid values.\n",
    "\n",
    "boston_df_out = boston_df_o1[~((boston_df_o1 < (Q1 - 1.5 * IQR)) |(boston_df_o1 > (Q3 + 1.5 *IQR))).any(axis=1)]\n",
    "\n",
    "boston_df_out.shape\n",
    "\n",
    "**Quantile function:** Use quantile() to remove amount of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11288960",
   "metadata": {},
   "source": [
    "### 8. What are the various central inclination measures? Why does mean vary too much from median in certain data sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8496e83e",
   "metadata": {},
   "source": [
    "Mean, Median and Mode are Central Inclination Measures. Mean varies more than Median due to presence of outliers, as mean is averaging all points while median in like finding a middle number."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bec338e",
   "metadata": {},
   "source": [
    "### 9. Describe how a scatter plot can be used to investigate bivariate relationships. Is it possible to find outliers using a scatter plot?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78160f",
   "metadata": {},
   "source": [
    "A Scatter Plot (aka scatter chart, scatter graph) uses dots to represent values for two different numeric variables. The position of each dot on the horizontal and vertical axis indicates values for an individual data point. So this visualization gives us the idea of bivariate relationship.\n",
    "\n",
    "Scatter plot can also help finding outliers as outliers can be visualized at farther distance than regular data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db562f7",
   "metadata": {},
   "source": [
    "### 10. Describe how cross-tabs can be used to figure out how two variables are related."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f13f357",
   "metadata": {},
   "source": [
    "Cross tabulation is a method to quantitatively analyze the relationship between multiple variables. Also known as contingency tables or cross tabs, cross tabulation groups variables to understand the correlation between different variables. It also shows how correlations change from one variable grouping to another."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
